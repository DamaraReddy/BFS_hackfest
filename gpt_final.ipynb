{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "import time\n",
    "from azure.storage.blob import ContainerClient\n",
    "from openai import AzureOpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set up Azure Blob Storage connection\n",
    "connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "container_name = os.getenv(\"CONTAINER_NAME\")  # Replace with your container name\n",
    "container_client = ContainerClient.from_connection_string(\n",
    "    conn_str=connection_string,\n",
    "    container_name=container_name\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract text from a PDF file stream\n",
    "def extract_text_from_pdf(file_stream):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        pdf_reader = PyPDF2.PdfReader(file_stream)\n",
    "        for page in pdf_reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_json(file_stream):\n",
    "\n",
    "    earning_call_transcript = extract_text_from_pdf(file_stream)\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "      azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "      api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "      api_version=\"2024-05-01-preview\"\n",
    "    )\n",
    "\n",
    "    with open(\"prompt.txt\", 'r') as prompt:\n",
    "        prompt = prompt.read()\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please provide output in a JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(earning_call_transcript=earning_call_transcript)}\n",
    "    ]\n",
    "\n",
    "\n",
    "    retries = 1\n",
    "    while retries <= 3:\n",
    "        try:\n",
    "            # print(\"getting json...\")\n",
    "            response = client.chat.completions.create(\n",
    "                model = os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "                messages = messages\n",
    "            )\n",
    "            response = response.choices[0].message.content\n",
    "            print(f\"done - {response}\")\n",
    "            return response # how_respose.text\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries > 3:\n",
    "                print(\"!!!!!Couldn't Resolve!!!!!!\")\n",
    "                return None\n",
    "            print(f\"Error Occoured: {e}\\n Retrying...{retries}\")\n",
    "            time.sleep(15)\n",
    "\n",
    "def process_blob(blob, k=1, retries=2,):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            stream = io.BytesIO()\n",
    "            print(f\"File_NAME = {blob.name}\")\n",
    "            container_client.download_blob(blob).readinto(stream)\n",
    "            op = get_json(stream)\n",
    "            if op:\n",
    "                op = json.loads(op[op.index(\"{\"):len(op)-op[::-1].index(\"}\")])\n",
    "                if op.get(\"capex\"):  # Check if capex is not empty\n",
    "                    return op\n",
    "                else:\n",
    "                    print(f\"Capex is empty. Retrying for blob {blob.name}...\")\n",
    "            attempt += 1\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing blob {blob.name}: {e}\")\n",
    "            return None\n",
    "    print(f\"Max retries reached for blob {blob.name}.\")\n",
    "    return None\n",
    "\n",
    "def get_capex_info(companies):\n",
    "    final_json = []\n",
    "    blob_list = list(container_client.list_blobs())[:] #limit here\n",
    "    blob_list = [blob for blob in blob_list if blob.name.strip().split('/')[0] in companies]\n",
    "    print(f\"NUMBER OF FILES: {len(blob_list)}\")\n",
    "    completed = 0\n",
    "    # Using ThreadPoolExecutor for parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_blob = {executor.submit(process_blob, blob): blob for blob in blob_list}\n",
    "        # Iterate over completed futures\n",
    "        for future in as_completed(future_to_blob):\n",
    "            blob = future_to_blob[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    op = result\n",
    "                    if op:  # Ensure op is not None\n",
    "                        completed += 1\n",
    "                        print(f\"{completed} files completed.\")\n",
    "                        print(op, \"\\n\\n\") #, how)\n",
    "                        final_json.append(op)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing result for blob {blob.name}: {e}\")\n",
    "\n",
    "    # Ensure final_json contains valid data\n",
    "    final_json = [item for item in final_json if isinstance(item, dict)]\n",
    "    if final_json:  # Check if final_json is not empty\n",
    "        df = pd.DataFrame(final_json)\n",
    "        print(f\"Total {completed} files completed.\")\n",
    "        print(f\"Processing completed. Results saved to df.\")\n",
    "        return df, final_json\n",
    "    else:\n",
    "        print(\"No valid data to save to df.\")\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df['company'] = df['company'].replace({\n",
    "    'Amazon': 'Amazon.com',\n",
    "    'Amazon.com, Inc.': 'Amazon.com',\n",
    "    'Alphabet':'Alphabet Inc.',\n",
    "    'Alphabet Inc':'Alphabet Inc.',\n",
    "    'Amazon.com Inc.': 'Amazon.com',\n",
    "    'Goldman Sachs' : 'Goldman Sachs Group, Inc.',\n",
    "    'The Goldman Sachs Group, Inc.': 'Goldman Sachs Group, Inc.',\n",
    "    'Goldman Sachs Group':'Goldman Sachs Group, Inc.',\n",
    "    'Tesla' : 'Tesla Inc.',\n",
    "    'Tesla, Inc.':'Tesla Inc.',\n",
    "    'Tesla Motors, Inc.': 'Tesla Inc.',\n",
    "    'Tesla Motors':'Tesla Inc.',\n",
    "    'Valero Energy Corporation': 'Valero Energy',\n",
    "    'Cardinal Health':'Cardinal Health, Inc.',\n",
    "    'BERKSHIRE HATHAWAY INC.': 'Berkshire Hathaway Inc.',\n",
    "    'Berkshire Hathaway Inc' : 'Berkshire Hathaway Inc.',\n",
    "    '\"Cardinal Health, Inc.\"':'Cardinal Health, Inc.',\n",
    "    'Bank of America Corporation': 'Bank of America',\n",
    "    'CVS Health Corp': 'CVS Health Corporation',\n",
    "    'CVS Health':'CVS Health Corporation',\n",
    "    'Cigna Corporation':'CIGNA', \n",
    "    'Cigna Corp.':'CIGNA', \n",
    "    'Cigna Corp':'CIGNA',\n",
    "      'CI':'CIGNA',\n",
    "      'CIGNA Corporation':'CIGNA',\n",
    "      'Cigna':'CIGNA', \n",
    "      'Cigna Group':'CIGNA',\n",
    "      'The Cigna Group':'CIGNA', \n",
    "      'Citigroup Inc.':'Citi',\n",
    "      'Citigroup Inc':'Citi',\n",
    "      'CMCSA':'Comcast',\n",
    "      'Comcast Corporation':'Comcast',\n",
    "      'Comcast Corp':'Comcast',\n",
    "      'WellPoint':'Wellpoint Inc',\n",
    "      'WellPoint':'Wellpoint Inc.',\n",
    "      'Anthem Inc': 'Anthem Inc.', \n",
    "    'Elevance Health':'Elevance Health Inc', \n",
    "    'Exxon Mobil Corporation':'ExxonMobil',\n",
    "      'ExxonMobil Corporation':'ExxonMobil',\n",
    "       'Ford Motor Company':'Ford Motor', \n",
    "       'Ford Motor Co':'Ford Motor',\n",
    "       'Ford Motor Co.':'Ford Motor',\n",
    "        'Humana Inc':'Humana Inc.',\n",
    "       'JPMorgan Chase & Co':'JPMorgan Chase & Co.',\n",
    "       'JPMorgan Chase':'JPMorgan Chase & Co.',\n",
    "       'McKesson Corporation':'McKesson' , \n",
    "       'McKESSON':'McKesson',\n",
    "       'McKESSON CORPORATION':'McKesson',  \n",
    "       'McKesson Corp.':'McKesson',\n",
    "       'McKesson Corp':'McKesson',\n",
    "       'Walgreens Boots Alliance':'Walgreens Boots Alliance Inc.',\n",
    "       'Walgreens Boots Alliance Inc':'Walgreens Boots Alliance Inc.', \n",
    "       'Wal-Mart Stores, Inc.':'Walmart', \n",
    "      'WAL-MART STORES, INC':'Walmart',\n",
    "       'Walmart Inc.':'Walmart', \n",
    "       'WAL-MART STORES, INC.':'Walmart',\n",
    "       'WAL-MART STORES, INC. (NYSE: WMT)':'Walmart', \n",
    "       'Walmart, Inc.':'Walmart',\n",
    "      \n",
    "})\n",
    "\n",
    "    df['capex'] = df['capex'].replace({ 'Not provided in the report':'-', 'nan':'-' ,'Not provided': '-', 'not available':'-','To be determined':'-','[Data Not Provided]':'-','Not Provided': '-','Not mentioned in the report':'-','X':'-', 'Not available': '-',  'Not specified': '-', 'n/a': '-', 'nan': '-','X.XX': '-','Not provided in the Report':'-','Not specified in the provided document':'-','Not Provided in the Report':'-','Not available in the provided document':'-','Not Available' :'-','[figures not provided]':'-', 'Not specified in the text provided': '-','Not mentioned' : '-','Not disclosed':'-'})\n",
    "    df['company'] = df['company'].str.replace('\"', ' ', regex=False)\n",
    "    df['year'] = df['year'].replace({'FY16' :'2016', 'FY21':'2021', 'FY20':'2020', 'FY19':'2019', 'FY23':'2023', 'FY24':'2024', 'FY2024':'2024', 'FY17':'2017', 'Q3 FY15':'2015', 'Q1 FY18' : '2018', 'Q1 FY21':'2021'})\n",
    "    df['quarter'] = df['quarter'].replace({'First Quarter': 'Q1', '2': 'Q2', 'Second Quarter': 'Q2', 'Third Quarter': 'Q3', '3rd Quarter':'Q3', '1':'Q1', '4th':'Q4', '2nd Quarter':'Q2', '2Q':'Q2', '3Q':'Q3', 'Fourth Quarter' : 'Q4','Fourth':'Q4','fourth':'Q4', 'Second':'Q2','4': 'Q4','First':'Q1', '4Q':'Q4','4':'Q4', 'Third':'Q3', '1Q':'Q1'})\n",
    "    \n",
    "    # Save the rearranged DataFrame to a new CSV file\n",
    "    print(f\"cleaned data saved\")# to {output_file}.\")\n",
    "    return df\n",
    "\n",
    "def rearrange_df(df):\n",
    "    # Convert 'quarter' and 'year' columns into a single 'Quarter-Year' column with an underscore\n",
    "    df['Quarter-Year'] = df['quarter'] + \"_\" + df['year'].astype(str)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df = df.pivot_table(index='company', columns='Quarter-Year', values='capex', aggfunc='first')\n",
    "\n",
    "    # Reset the index to make 'company' a column instead of an index\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    # Define a function to sort columns in the desired order\n",
    "    def sort_columns(df):\n",
    "        # Extract the current columns\n",
    "        columns = df.columns.tolist()\n",
    "\n",
    "        # Extract the company column and the Quarter-Year columns\n",
    "        company_col = columns[0]\n",
    "        quarter_cols = columns[1:]\n",
    "\n",
    "        # Generate sorted columns list: Start with the most recent quarters\n",
    "        sorted_quarters = sorted(quarter_cols, key=lambda x: (x.split('_')[1], x.split('_')[0]), reverse=True)\n",
    "\n",
    "        # Combine sorted columns with the company column\n",
    "        sorted_columns = [company_col] + sorted_quarters\n",
    "        return sorted_columns\n",
    "\n",
    "    # Reorder the columns\n",
    "    sorted_columns = sort_columns(pivot_df)\n",
    "    pivot_df = pivot_df[sorted_columns]\n",
    "    pivot_df['company'].unique()\n",
    "    pivot_df['company'] = pivot_df['company'].str.replace('\"', ' ', regex=False)\n",
    "\n",
    "    print(f\"Rearranged data saved\")# to {output_file}.\")\n",
    "    return pivot_df\n",
    "\n",
    "def final_process(df):\n",
    "    # Define a function to compare capex values between consecutive columns\n",
    "    def compare_columns(row):\n",
    "        comparisons = []\n",
    "        for i in range(1, len(row) - 1):  # Skip the 'company' column\n",
    "            current_value = row[i]\n",
    "            next_value = row[i + 1]\n",
    "\n",
    "            if pd.isna(current_value) or pd.isna(next_value):\n",
    "                comparisons.append(\"DNA\")#(\"Data not available\")\n",
    "            else:\n",
    "                try:\n",
    "                    current_value = float(current_value)\n",
    "                    next_value = float(next_value)\n",
    "                    if next_value < current_value:\n",
    "                        comparisons.append(\"Increase\")\n",
    "                    elif next_value > current_value:\n",
    "                        comparisons.append(\"Decrease\")\n",
    "                    else:\n",
    "                        comparisons.append(\"Unchanged\")\n",
    "                except ValueError:\n",
    "                    comparisons.append(\"DNA\")#(\"Data not available\")\n",
    "\n",
    "        return comparisons\n",
    "\n",
    "    # Apply the comparison function to each row\n",
    "    comparison_results = df.apply(lambda row: compare_columns(row), axis=1)\n",
    "\n",
    "    # Replace the original values in the DataFrame with the comparison results\n",
    "    for i, col in enumerate(df.columns[1:-1]):  # Exclude 'company' and the last quarter\n",
    "        df[col] = comparison_results.apply(lambda x: x[i])\n",
    "\n",
    "    # # Save the comparison results to a new CSV file\n",
    "    # output_file = \"capex_comparison_results.csv\"\n",
    "    # df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Capex comparison results saved\") #to {output_file}.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = []\n",
    "raw_company_df = []\n",
    "raw_json = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########processing--Alphabet##########\n",
      "NUMBER OF FILES: 14\n",
      "File_NAME = Alphabet/2021/2021q1-alphabet-earnings-release.pdf\n",
      "done - {\n",
      "  \"company\": \"Alphabet\",\n",
      "  \"quarter\": \"Q1\",\n",
      "  \"year\": \"2021\",\n",
      "  \"capex\": \"5.942\"\n",
      "}\n",
      "File_NAME = Alphabet/2021/2021q2-alphabet-earnings-release.pdf\n",
      "1 files completed.\n",
      "{'company': 'Alphabet', 'quarter': 'Q1', 'year': '2021', 'capex': '5.942'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q2\",\n",
      "  \"year\": \"2021\",\n",
      "  \"capex\": \"11.438\"\n",
      "}\n",
      "File_NAME = Alphabet/2021/2021q3-alphabet-earnings-release.pdf\n",
      "2 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q2', 'year': '2021', 'capex': '11.438'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q3\",\n",
      "  \"year\": \"2021\",\n",
      "  \"capex\": \"6.819\"\n",
      "}\n",
      "File_NAME = Alphabet/2021/2021q4-alphabet-earnings-release.pdf\n",
      "3 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q3', 'year': '2021', 'capex': '6.819'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet\",\n",
      "  \"quarter\": \"Q4\",\n",
      "  \"year\": \"2021\",\n",
      "  \"capex\": \"N/A\"\n",
      "}\n",
      "File_NAME = Alphabet/2022/2022q1-alphabet-earnings-release.pdf\n",
      "4 files completed.\n",
      "{'company': 'Alphabet', 'quarter': 'Q4', 'year': '2021', 'capex': 'N/A'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q1\",\n",
      "  \"year\": \"2022\",\n",
      "  \"capex\": \"Considered investments in Capex, R&D, and talent\"\n",
      "}\n",
      "File_NAME = Alphabet/2022/2022q2-alphabet-earnings-release.pdf\n",
      "5 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q1', 'year': '2022', 'capex': 'Considered investments in Capex, R&D, and talent'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet\",\n",
      "  \"quarter\": \"Q2\",\n",
      "  \"year\": \"2022\",\n",
      "  \"capex\": \"6.828\"\n",
      "}\n",
      "File_NAME = Alphabet/2022/2022q3-alphabet-earnings-release.pdf\n",
      "6 files completed.\n",
      "{'company': 'Alphabet', 'quarter': 'Q2', 'year': '2022', 'capex': '6.828'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q3\",\n",
      "  \"year\": \"2022\",\n",
      "  \"capex\": \"23,890\"\n",
      "}\n",
      "File_NAME = Alphabet/2022/2022q4-alphabet-earnings-release.pdf\n",
      "7 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q3', 'year': '2022', 'capex': '23,890'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q4\",\n",
      "  \"year\": \"2022\",\n",
      "  \"capex\": \"31,485\"\n",
      "}\n",
      "File_NAME = Alphabet/2023/2023q2-alphabet-earnings-release.pdf\n",
      "8 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q4', 'year': '2022', 'capex': '31,485'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q2\",\n",
      "  \"year\": \"2023\",\n",
      "  \"capex\": \"13.177\"\n",
      "}\n",
      "File_NAME = Alphabet/2023/2023q3-alphabet-earnings-release.pdf\n",
      "9 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q2', 'year': '2023', 'capex': '13.177'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet\",\n",
      "  \"quarter\": \"Q3\",\n",
      "  \"year\": \"2023\",\n",
      "  \"capex\": \"21,232\"\n",
      "}\n",
      "File_NAME = Alphabet/2023/2023q4-alphabet-earnings-release.pdf\n",
      "10 files completed.\n",
      "{'company': 'Alphabet', 'quarter': 'Q3', 'year': '2023', 'capex': '21,232'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q4\",\n",
      "  \"year\": \"2023\",\n",
      "  \"capex\": \"32,251\"\n",
      "}\n",
      "File_NAME = Alphabet/2023/goog-exhibit-99-1-q1-2023-19.pdf\n",
      "11 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q4', 'year': '2023', 'capex': '32,251'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q1\",\n",
      "  \"year\": \"2023\",\n",
      "  \"capex\": \"N/A\"\n",
      "}\n",
      "File_NAME = Alphabet/2024/2024q1-alphabet-earnings-release-pdf.pdf\n",
      "12 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q1', 'year': '2023', 'capex': 'N/A'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q1\",\n",
      "  \"year\": \"2024\",\n",
      "  \"capex\": \"12,012\"\n",
      "}\n",
      "File_NAME = Alphabet/2024/2024q2-alphabet-earnings-release.pdf\n",
      "13 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q1', 'year': '2024', 'capex': '12,012'} \n",
      "\n",
      "\n",
      "done - {\n",
      "  \"company\": \"Alphabet Inc.\",\n",
      "  \"quarter\": \"Q2\",\n",
      "  \"year\": \"2024\",\n",
      "  \"capex\": \"13.186\"\n",
      "}\n",
      "14 files completed.\n",
      "{'company': 'Alphabet Inc.', 'quarter': 'Q2', 'year': '2024', 'capex': '13.186'} \n",
      "\n",
      "\n",
      "Total 14 files completed.\n",
      "Processing completed. Results saved to df.\n",
      "cleaned data saved\n",
      "Rearranged data saved\n",
      "Capex comparison results saved\n",
      "$$$$$$$$$$processed--Alphabet$$$$$$$$$$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2272655\\AppData\\Local\\Temp\\ipykernel_31200\\1720823673.py:113: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  current_value = row[i]\n",
      "C:\\Users\\2272655\\AppData\\Local\\Temp\\ipykernel_31200\\1720823673.py:114: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  next_value = row[i + 1]\n"
     ]
    }
   ],
   "source": [
    "# all_companies = [\n",
    "# \"Alphabet\",\n",
    "# \"Amazon\",\n",
    "# \"Berkshire Hathaway\",\n",
    "# \"Cardinal Health\",\n",
    "# \"Centene\",\n",
    "# \"Chevron\",\n",
    "# \"Comcast\",\n",
    "# \"ExxonMobil\",\n",
    "# \"Tesla\",\n",
    "# \"UnitedHealth Group\",\n",
    "# \"Valero Energy\",\n",
    "# \"Walgreens Boots Alliance\",\n",
    "# \"Wallmart\"\n",
    "# ]\n",
    "all_companies = [\"Alphabet\"]\n",
    "for company in all_companies:\n",
    "    print(f\"{'#'*10}processing--{company}{'#'*10}\")\n",
    "    csv_df, json_data = get_capex_info([company])\n",
    "    raw_json.append(json_data)\n",
    "    cleaned_df = clean_df(csv_df)\n",
    "    rearranged_df = rearrange_df(cleaned_df)\n",
    "    rearranged_df.to_csv(f\"{company}.csv\")\n",
    "    raw_company_df.append(rearranged_df.copy(deep=True))\n",
    "    final_df = final_process(rearranged_df)\n",
    "    final_df.to_csv(f\"final_{company}.csv\")\n",
    "    company_df.append(final_df.copy(deep=True))\n",
    "    print(f\"{'$'*10}processed--{company}{'$'*10}\")\n",
    "\n",
    "final_analysis = pd.concat(company_df)\n",
    "final_analysis.to_csv(\"final_analysis_final_test_gpt_aplha.csv\")\n",
    "raw_company_analysis = pd.concat(raw_company_df)\n",
    "raw_company_analysis.to_csv(\"final_raw_company_analysis__final_test_gpt_aplha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Quarter-Year</th>\n",
       "      <th>company</th>\n",
       "      <th>Q2_2024</th>\n",
       "      <th>Q1_2024</th>\n",
       "      <th>Q4_2023</th>\n",
       "      <th>Q3_2023</th>\n",
       "      <th>Q2_2023</th>\n",
       "      <th>Q1_2023</th>\n",
       "      <th>Q4_2022</th>\n",
       "      <th>Q3_2022</th>\n",
       "      <th>Q2_2022</th>\n",
       "      <th>Q1_2022</th>\n",
       "      <th>Q4_2021</th>\n",
       "      <th>Q3_2021</th>\n",
       "      <th>Q2_2021</th>\n",
       "      <th>Q1_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>Increase</td>\n",
       "      <td>5.942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Quarter-Year        company Q2_2024 Q1_2024 Q4_2023 Q3_2023 Q2_2023 Q1_2023  \\\n",
       "0             Alphabet Inc.     DNA     DNA     DNA     DNA     DNA     DNA   \n",
       "\n",
       "Quarter-Year Q4_2022 Q3_2022 Q2_2022 Q1_2022 Q4_2021   Q3_2021   Q2_2021  \\\n",
       "0                DNA     DNA     DNA     DNA     DNA  Decrease  Increase   \n",
       "\n",
       "Quarter-Year Q1_2021  \n",
       "0              5.942  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Quarter-Year</th>\n",
       "      <th>company</th>\n",
       "      <th>Q2_2024</th>\n",
       "      <th>Q1_2024</th>\n",
       "      <th>Q4_2023</th>\n",
       "      <th>Q3_2023</th>\n",
       "      <th>Q2_2023</th>\n",
       "      <th>Q1_2023</th>\n",
       "      <th>Q4_2022</th>\n",
       "      <th>Q3_2022</th>\n",
       "      <th>Q2_2022</th>\n",
       "      <th>Q1_2022</th>\n",
       "      <th>Q4_2021</th>\n",
       "      <th>Q3_2021</th>\n",
       "      <th>Q2_2021</th>\n",
       "      <th>Q1_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>13.186</td>\n",
       "      <td>12,012</td>\n",
       "      <td>32,251</td>\n",
       "      <td>21,232</td>\n",
       "      <td>13.177</td>\n",
       "      <td>N/A</td>\n",
       "      <td>31,485</td>\n",
       "      <td>23,890</td>\n",
       "      <td>6.828</td>\n",
       "      <td>Considered investments in Capex, R&amp;D, and talent</td>\n",
       "      <td>N/A</td>\n",
       "      <td>6.819</td>\n",
       "      <td>11.438</td>\n",
       "      <td>5.942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Quarter-Year        company Q2_2024 Q1_2024 Q4_2023 Q3_2023 Q2_2023 Q1_2023  \\\n",
       "0             Alphabet Inc.  13.186  12,012  32,251  21,232  13.177     N/A   \n",
       "\n",
       "Quarter-Year Q4_2022 Q3_2022 Q2_2022  \\\n",
       "0             31,485  23,890   6.828   \n",
       "\n",
       "Quarter-Year                                           Q1_2022 Q4_2021  \\\n",
       "0             Considered investments in Capex, R&D, and talent     N/A   \n",
       "\n",
       "Quarter-Year Q3_2021 Q2_2021 Q1_2021  \n",
       "0              6.819  11.438   5.942  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_company_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
